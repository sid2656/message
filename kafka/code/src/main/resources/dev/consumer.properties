#消费者Consumer参数
#是用户特定的字符串，用来在每次请求中帮助跟踪调用。它应该可以逻辑上确认产生这个请求的应用
#client.id
#不需要设置，一般自动产生
#consumer.id
#用来唯一标识consumer进程所在组的字符串
#group.id
#broker的列表
zookeeper.connect=192.168.174.191:2181
#网络请求的超时限制。真实的超时限制是   max.fetch.wait+socket.timeout.ms
#socket.timeout.ms=301000
#socket用于接收网络请求的缓存大小
#socket.receive.buffer.bytes=65534
#每次fetch请求中，针对每次fetch消息的最大字节数
#fetch.message.max.bytes=1048576
#用于fetch数据的fetcher线程数
#num.consumer.fetchers=1
#如果为真，consumer所fetch的消息的offset将会自动的同步到zookeeper
#auto.commit.enable=true
#consumer向zookeeper提交offset的频率，单位是秒
auto.commit.interval.ms=1000
#用于缓存消息的最大数目，以供consumption。每个chunk必须和fetch.message.max.bytes相同
#queued.max.message.chunks=2
#当新的consumer加入到consumer  group时，consumers集合试图重新平衡分配到每个consumer的partitions数目；此选项设置尝试次数
#rebalance.max.retries=4
#每次fetch请求时，server应该返回的最小字节数。如果没有足够的数据返回，请求会等待，直到足够的数据才会返回
#fetch.min.bytes=1
#如果没有足够的数据能够满足fetch.min.bytes，则此项配置是指在应答fetch请求之前，server会阻塞的最大时间
#fetch.wait.max.ms=100
#在重试reblance之前backoff时间
#rebalance.backoff.ms=2000
#在试图确定某个partition的leader是否失去他的leader地位之前，需要等待的backoff时间
#refresh.leader.backoff.ms=200
#zookeeper中没有初始化的offset时，如果offset是以下值的回应：
#smallest：自动复位offset为smallest的offset；
#largest：自动复位offset为largest的offset；
#anything  else：向consumer抛出异常
auto.offset.reset=largest
#如果没有消息可用，即使等待特定的时间之后也没有，则抛出超时异常
consumer.timeout.ms=10000
#是否将内部topics的消息暴露给consumer
#exclude.internal.topics=true
#选择向consumer 流分配partitions的策略，可选值：range，roundrobin
#partition.assignment.strategy=range
#zookeeper 会话的超时限制。如果consumer在这段时间内没有向zookeeper发送心跳信息，则它会被认为挂掉了
zookeeper.session.timeout.ms=6000
#客户端在建立通zookeeper连接中的最大等待时间6000
zookeeper.connection.timeout.ms=6000
#ZK follower可以落后ZK leader的最大时间
zookeeper.sync.time.ms=2000
#用于存放offsets的地点： zookeeper或者kafka
#offsets.storage=zookeeper
#重新连接offsets channel或者是重试失败的offset的fetch/commit请求的backoff时间
#offsets.channel.backoff.ms=1000
#当读取offset的fetch/commit请求回应的socket 超时限制。此超时限制是被consumerMetadata请求用来请求offset管理
#offsets.channel.socket.timeout.ms=10000
#重试offset commit的次数。这个重试只应用于offset  commits在shut-down之间。他
#offsets.commit.max.retries=5
#如果使用“kafka”作为offsets.storage，你可以二次提交offset到zookeeper(还有一次是提交到kafka）。
#在zookeeper-based的offset  storage到kafka-based的offset storage迁移时，这是必须的。
#对任意给定的consumer  group来说，比较安全的建议是当完成迁移之后就关闭这个选项
#dual.commit.enabled=true
#在“range”和“roundrobin”策略之间选择一种作为分配partitions给consumer 数据流的策略； 
#循环的partition分配器分配所有可用的partitions以及所有可用consumer  线程。
#它会将partition循环的分配到consumer线程上。如果所有consumer实例的订阅都是确定的，则partitions的划分是确定的分布。
#循环分配策略只有在以下条件满足时才可以：
#（1）每个topic在每个consumer实力上都有同样数量的数据流。
#（2）订阅的topic的集合对于consumer  group中每个consumer实例来说都是确定的。
#partition.assignment.strategy=range
# 指定序列化处理类(mafka client API调用说明-->3.序列化约定wiki)，默认为kafka.serializer.DefaultDecoder,即byte[]
derializer.class=kafka.serializer.DefaultDecoder
