#旧生产者productor参数
#指定kafka节点列表，用于获取metadata，不必全部指定
metadata.broker.list=192.168.174.191:9092,192.168.174.191:9093,192.168.174.191:9094
# 指定分区处理类。默认kafka.producer.DefaultPartitioner，表通过key哈希到对应分区
#partitioner.class=com.meituan.mafka.client.producer.CustomizePartitioner
# 是否压缩，默认0表示不压缩，1表示用gzip压缩，2表示用snappy压缩。压缩后消息中会有头来指明消息压缩类型，故在消费者端消息解压是透明的无需指定。
compression.codec=none
# 指定序列化处理类(mafka client API调用说明-->3.序列化约定wiki)，默认为kafka.serializer.DefaultEncoder,即byte[]
# serializer.class=kafka.serializer.DefaultEncoder
serializer.class=kafka.serializer.StringEncoder
# 如果要压缩消息，这里指定哪些topic要压缩消息，默认empty，表示不压缩。
#compressed.topics=
########### request ack ###############
# producer接收消息ack的时机.默认为0. 
# 0: producer不会等待broker发送ack 
# 1: 当leader接收到消息之后发送ack 
# 2: 当所有的follower都同步消息成功后发送ack. 
request.required.acks=0
# 在向producer发送ack之前,broker允许等待的最大时间 
# 如果超时,broker将会向producer发送一个error ACK.意味着上一次消息因为某种 
# 原因未能成功(比如follower未能同步成功)  10000
request.timeout.ms=10000
########## end #####################
# 同步还是异步发送消息，默认“sync”表同步，"async"表异步。异步可以提高发送吞吐量,
# 也意味着消息将会在本地buffer中,并适时批量发送，但是也可能导致丢失未发送过去的消息
producer.type=sync
############## 异步发送 (以下四个异步参数可选) ####################
# 在async模式下,当message被缓存的时间超过此值后,将会批量发送给broker,默认为5000ms
# 此值和batch.num.messages协同工作.
queue.buffering.max.ms=5000
# 在async模式下,producer端允许buffer的最大消息量
# 无论如何,producer都无法尽快的将消息发送给broker,从而导致消息在producer端大量沉积
# 此时,如果消息的条数达到阀值,将会导致producer端阻塞或者消息被抛弃，默认为10000
queue.buffering.max.messages=20000
# 如果是异步，指定每次批量发送数据量，默认为200
batch.num.messages=500
# 当消息在producer端沉积的条数达到"queue.buffering.max.meesages"后 
# 阻塞一定时间后,队列仍然没有enqueue(producer仍然没有发送出任何消息) 
# 此时producer可以继续阻塞或者将消息抛弃,此timeout值用于控制"阻塞"的时间 
# -1: 无阻塞超时限制,消息不会被抛弃 
# 0:立即清空队列,消息被抛弃 
queue.enqueue.timeout.ms=-1
################ end ###############
# 当producer接收到error ACK,或者没有接收到ACK时,允许消息重发的次数 
# 因为broker并没有完整的机制来避免消息重复,所以当网络异常时(比如ACK丢失) 
# 有可能导致broker接收到重复的消息,默认值为3.
message.send.max.retries=3
# producer刷新topic metada的时间间隔,producer需要知道partition leader的位置,以及当前topic的情况 
# 因此producer需要一个机制来获取最新的metadata,当producer遇到特定错误时,将会立即刷新 
# (比如topic失效,partition丢失,leader失效等),此外也可以通过此参数来配置额外的刷新机制，默认值600000 
topic.metadata.refresh.interval.ms=60000


##新生产者productor参数
##当向server发出请求时，这个字符串会发送给server。目的是能够追踪请求源头；这项应用可以设置任意字符串，因为没有任何功能性的目的，除了记录和跟踪
##client.id
##broker的列表
#bootstrap.servers=192.168.174.191:9092,192.168.174.191:9003,192.168.174.191:9094
## producer接收消息ack的时机.默认为0. 
## 0: producer不会等待broker发送ack 
## 1: 当leader接收到消息之后发送ack 
## 2: 当所有的follower都同步消息成功后发送ack. 
#acks=0 
##设置生产者缓冲区大大小byte
#buffer.memory=33554432
##如果要压缩消息，这里指定哪些topic要压缩消息，正确的选项值是none、gzip、snappy默认none，表示不压缩
#compression.type=none
## 当producer接收到error ACK,或者没有接收到ACK时,允许消息重发的次数 
## 因为broker并没有完整的机制来避免消息重复,所以当网络异常时(比如ACK丢失) 
## 有可能导致broker接收到重复的消息,默认值为0
#retries=0
##如果是异步，指定每次批量发送数据量，默认为16384
#batch.size=16384
##设置批处理抓取延迟，默认为0
#linger.ms=0
##请求的最大限制
#max.request.size=1048576
##接收数据的缓冲块大小
#receive.buffer.bytes=32768
##发送数据的缓冲块大小
#send.buffer.bytes=131072
##网络应答最大延迟时间
#timeout.ms=30000
##如果数据写到一半发现block满了，是写到新的block中还是抛出异常，默认为true表示写到新的块中
#block.on.buffer.full=true
##设置获取分块数据的最大延迟时间
#metadata.fetch.timeout.ms=60000
##每个多少毫秒刷新快信息
#metadata.max.age.ms=300000
##metric.reporters
##metrics.num.samples	int	2
##metrics.sample.window.ms	long	30000
##连接失败时，当我们重新连接时的等待时间。这避免了客户端反复重连
#reconnect.backoff.ms=10
##在试图重试失败的produce请求之前的等待时间。避免陷入发送-失败的死循环中。
#retry.backoff.ms=100
